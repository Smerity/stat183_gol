<head>
  <style type="text/css">
    body, blockquote{
      margin-left:20px;
      margin-right:20px; 
      font-size:14pt; 
      font-family:Calibri,Arial;
    }
    div.title {
      margin-left:auto;
      margin-right:auto;
      text-align:center; 
      line-spacing:10px;
      font-weight:900; 
      font-size:20pt;
    }
    div.pattern-example {
      line-spacing:5px; 
      letter-spacing:10px; 
      font-weight:900;
    }
    div#three-col { 
      width:300px; 
    }
    div#col1 {
      position:relative; 
      float:left; 
      width:60px; 
      display:table-column;
    }
    div#col2 {
      position:relative; 
      float:left; 
      padding-left:10px;
      padding-top:20px;
      vertical-align:middle; 
      width:150px; 
      display:table-column;
    }
    div#col3 {
      position:relative; 
      float:left; 
      width:60px; 
      display:table-column;
    }
    div.intro {
      margin-left:50px;
      margin-right:50px;
      font-size:16pt;
    }
    .big-indent { margin-left:60px;}
    .text-line { clear:both;}
    span.crimson, a { color:maroon;}
    span.standout { color:blue;}
    span.ltgray { color:gray;}
    span.section-head {
      margin-top:20px; 
      color:maroon; 
      font-size:20pt; 
      font-weight:900;
    }
    img {
      padding-top: 15px; 
      padding-bottom: 15px;
    }
    li {margin-top:10px; line-spacing:15px;}
    code {font-size: 12pt;}
  </style>
</head>




<div class="title">
  STAT183 Challenge:  <span class="crimson">Reverse Game of Life</span>
                      <span class="ltgray"> [week 3]</span> <br />
  <img src="http://schools-wikipedia.org/images/194/19479.png" /> <br />
  Strategy: <span class="crimson">"5x5, 4x4 offsets, ensembles, and forward"</span> <br />
  Team: <span class="crimson">Groeneveld, Merity, Randell</span> 
 <br /><br /></div>

Kaggle Game of Life competition
<br>

========================================================
<br>
<div class="intro"><b>Previously, on reversing Conway's Game of Life</b>:<br>
This week, we pursued three paths: a solution using 5x5 centered sub-boards, a solution using 4x4 offset boards, and an ensemble method that used our model of forward error for selecting the solution.
Ultimately we ran out of time to use the full ensemble method as the deadline approached, so we submitted a simple ensemble that used the 5x5 and 4x4 approaches. We believe this simple ensemble has improved our performance substantially.
</div>

<hr>


<span class="section-head">The 5x5 and 3x3 sub-board model</span>
<br />
Similar to last week's idea of 5x5 patterns, we expanded to combining our 5x5 model with 3x3 sub boards. If a 5x5 board showed up in our data less than 5 times, we would set the probability associated with that middle cell being on as negative so that we had a flag. Coming across this pattern again when running the algorithm, we would check to see if the value was between -0.9 and 0.0. If it was, we would use the surrounding 3x3 pattern as the prediction probability of the board. If the value of it was between -0.9 and -1.0 we would then just set the middle pixel to be on because, even though the pattern showed up fewer than 5 times, we are reasonably certain that the middle cell should still be on. We checked this assumption over many cases.

<br />
<span class="section-head">The 4x4 offset sub-board model</span>
<br />
We base our second model upon that of Dmitri, Stephen, and Toan from last week. Their model used multiple 4x4 boxes that contain the target pixel and produced the prediction by averaging the predictions given by the individual boxes.

We performed a number of minor adjustments to their code, primarily enabling the saving of the produced probability distributions (lowering the time to redo experiments) and other minor improvements. We also ran the code for 20 million boards to generate the frequency information for each subset. Time was spent trying to parallelize the code using OpenMP in C++ but didn't result in significant improvements.

<br />
<span class="section-head">The 5x5 and 4x4 "simple" ensemble</span>
<br />
As each of our 4x4 and 5x5 models could produce a probability, we were interested in seeing what potential an ensemble could provide. As the two methods used substantially different information, they could be complementary. This indeed turned out to be the case.

The 4x4 offset method resulted in a performance of 0.1185 on the test set. The 5x5 method resulted in a performance of 0.12299. When the probabilty was averaged together and thresholded at 0.5 (i.e. $0.5 \times x + 0.5 \times y > 0.5$), the performance was 0.1159.

On further analysis, it was discovered that our models were less confident than they should have been. Taking the max() of our two methods resulted in 0.1169, only a slight loss from the 0.1159 above. Taking the min() of our two methods, however, resulted in a substantially worse 0.1247!

From this observation, we tried 'over-weighting' our two models, specifically $0.6 \times x + 0.6 \times y > 0.5$, and produced an ensemble resulting in a training performance of 0.1134.

We don't yet know whether this will hold true for the actual test set. Regardless, if this competition continued further, we would strongly recommend that all teams be required to produce a training and test probabilities file, allowing the easy creation and exploration of potential ensemble methods.

<span class="section-head">Ensemble method with forward error proxy</span>
<br />
We initially started this week by writing an ensemble method with most of the submission files from the previous week. Initial investigation into the correlation of forward error and actual prediction error yeilded about a 0.94 correlation, for all delta cases. We ran our ensemble and in our test submission on Friday it didn't perform as well as we had hoped. It only did a little bit better than the average of all our solution sets. In theory, we thought, we would do as worst as the best solution. So we looked into the correlation more, and noticed that for delta is 1 and 2 the correlation was about 0.96, but as delta increased the correlation went down to 0.90. We concluded perhaps this ensemble method would perform well for detla = 1,2 but not as well as delta grows. Unfortunately the nature of this ensemble method was such that we couldn't test how well we would do before submitting. Essentially we were access the power of the best team's algorithms through their solution sets, but we couldn't repoduce their algorithms on new data that we knew the solution for.
<br />
The general idea of the ensemble method is as follows: for every board in the test data, compute the forward error for every solution set we have and take the board with the least forward error as our new best prediction. As per the above discussion we ended up only running this on delta is 1 and 2, and just used the best solution's board for delta is 1,2 and 3. 
<br/>
We started by loading in all solution sets we wanted to iterate over. <b> In order to reproduce our code you will need files of the following name in your directory.</b> The file names are simply the overall error computed by Kaggle. They are ordered from best to worst total Kaggle prediction error.
<hr>
<code>BEGIN CODE</code>

```{r source, eval=FALSE, cache=FALSE}
setwd("~/Documents/SeniorSpring/Stat183/GameofLife/submissions/Reece_Andrew_BryanTonyAndrew/")
source("still-life-functions.R")
```
<br />
```{r, eval=FALSE, cache=FALSE}
df_test <- read.csv("test.csv")

# Load in our predictions to ensemble over
num_ensemble <- 5
df_1 <- read.csv("11568.csv")
df_2 <- read.csv("11623.csv")
df_3 <- read.csv("11720.csv")
df_4 <- read.csv("11777.csv")
df_5 <- read.csv("12121.csv")

# df_best will be by default our best prediction, we will update in place if we find a better
# prediction as by forward error
df_best <- df_1

lst = list(df_1,df_2,df_3,df_4,df_5)

```
<br />
For every board in every solution set, we start by pulling out the test board and the delta from the actual test data. We then proceed to let the default 'best board' equal the board given by the best solution. We then checked if the delta was in our range of valid deltas. If not we skip straight to letting the current default board be the best board prediction. If it was in the range we would then evolve the current solutions sets' board in question delta times. Checked if the forward error was less than the current minimum forward error, if so updated our best board prediction. Our entire best solution set prediction would live in the variable df_best.
<br />
```{r, eval=FALSE, cache=FALSE}
for(i in 1:50000){
  test_board <- df_test[i,]
  delta <- test_board[2]

  #Get rid of the delta column for the test board, for when we sum/calculate our forward error
  test_board["delta"] <- NULL
    
  # Just let the initial best board be the board in the first place df to initialize best_board.. need here for scope
  best_board <- lst[[1]][i,][2:401]
  if(delta<=2){
    min_err <- 400
      
    # Loop through all predictions for each board -- num_ensemble is the number of total prediction files we have
    for(j in 1:num_ensemble){
      # Pull out start board prediction -- q_board==question board
      q_board <- lst[[j]][i,][1:401]
      pred <- matrix(as.integer(q_board[2:401]),nrow=20,ncol=20)
      
      # Evolve board forward delta steps in order to calculate forward error
      k=0
      while(k < delta){
        pred <- update_board(pred)
        k <- k+1
      }
      
      # Now board is evolved, check the forward error
      error <- sum(test_board!=pred)
      
      if(error<min_err){     
          min_err <- error
          best_board <- q_board
      }
    }
  }
  
  df_best[i,] <- best_board 
}
```

</div>






















